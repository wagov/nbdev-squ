{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev_squ import api, clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIEM Query Utils\n",
    "\n",
    "> Python SIEM Query Utils nbdev edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "[![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/wagov/nbdev-squ/deploy.yaml.svg?logo=github)](https://github.com/wagov/nbdev-squ/actions/workflows/deploy.yaml) [![Python Packaging Index - Version](https://img.shields.io/pypi/v/nbdev-squ.svg?logo=pypi)](https://pypi.org/project/nbdev-squ/) [![OpenSSF Scorecard](https://img.shields.io/ossf-scorecard/github.com/wagov/nbdev-squ.svg?label=openssf%20scorecard)](https://securityscorecards.dev/viewer/?uri=github.com/wagov/nbdev-squ)\n",
    "\n",
    "Below is how to install in a plain python 3.12+ environment\n",
    "\n",
    "```sh\n",
    "pip install nbdev-squ\n",
    "```\n",
    "\n",
    "The installation can also be run in a notebook (we tend to use [JupyterLab Desktop](https://github.com/jupyterlab/jupyterlab-desktop) for local dev). The `SQU_CONFIG` env var indicates to nbdev_squ it should load the json secret *squconfig-`my_keyvault_tenantid`* from the `my_kevault_name` keyvault.\n",
    "\n",
    "```python\n",
    "%pip install nbdev-squ\n",
    "import os; os.environ[\"SQU_CONFIG\"] = \"{{ my_keyvault_name }}/{{ my_keyvault_tenantid }}\" \n",
    "\n",
    "from nbdev_squ import api\n",
    "# do cool notebook stuff with api\n",
    "```\n",
    "\n",
    "### Security considerations\n",
    "\n",
    "The contents of the keyvault secret are loaded into memory and cached in the [user_cache_dir](https://platformdirs.readthedocs.io/en/latest/api.html#cache-directory) which should be a temporary secure directory restricted to the single user. Please ensure that the system this library is used on disallows access and/or logging of the user cache directory to external locations, and is on an encrypted disk (a common approach is to use isolated VMs and workstations for sensitive activities)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: If you create/use a Github Codespace on any of the wagov repos, SQU_CONFIG should be configured automatically.*\n",
    "\n",
    "Before using, config needs to be loaded into `nbdev_squ.core.cache`, which can be done automatically from json in a keyvault by setting the env var `SQU_CONFIG` to `\"keyvault/tenantid\"`.\n",
    "\n",
    "```bash\n",
    "export SQU_CONFIG=\"{{ keyvault }}/{{ tenantid }}\"\n",
    "```\n",
    "\n",
    "Can be done in python before import from nbdev_squ as well:\n",
    "\n",
    "```python\n",
    "import os; os.environ[\"SQU_CONFIG\"] = \"{{ keyvault }}/{{ tenantid }}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev_squ import api\n",
    "import io, pandas\n",
    "\n",
    "# Load workspace info from datalake blob storage\n",
    "df = api.list_workspaces(fmt=\"df\"); print(df.shape)\n",
    "\n",
    "# Load workspace info from introspection of azure graph\n",
    "df = api.list_securityinsights(); print(df.shape)\n",
    "\n",
    "# Kusto query to Sentinel workspaces via Azure Lighthouse\n",
    "df = api.query_all(\"SecurityIncident | take 20\", fmt=\"df\"); print(df.shape)\n",
    "\n",
    "# Kusto queries to Sentinel workspaces via Azure Lighthouse (batches up to 100 queries at a time)\n",
    "df = api.query_all([\"SecurityAlert | take 20\" for a in range(10)]); print(df.shape)\n",
    "\n",
    "# Kusto query to ADX\n",
    "#df = api.adxtable2df(api.adx_query(\"kusto query | take 20\"))\n",
    "\n",
    "# General azure cli cmd\n",
    "api.azcli([\"config\", \"set\", \"extension.use_dynamic_install=yes_without_prompt\"])\n",
    "print(len(api.azcli([\"account\", \"list\"])))\n",
    "\n",
    "# Various pre-configured api clients\n",
    "\n",
    "# RunZero\n",
    "response = api.clients.runzero.get(\"/export/org/assets.csv\", params={\"search\": \"has_public:t AND alive:t AND (protocol:rdp OR protocol:vnc OR protocol:teamviewer OR protocol:telnet OR protocol:ftp)\"})\n",
    "pandas.read_csv(io.StringIO(response.text)).head(10)\n",
    "\n",
    "# Jira\n",
    "pandas.json_normalize(api.clients.jira.jql(\"updated > -1d\")[\"issues\"]).head(10)\n",
    "\n",
    "# AbuseIPDB\n",
    "api.clients.abuseipdb.check_ip(\"1.1.1.1\")\n",
    "\n",
    "# TenableIO\n",
    "pandas.DataFrame(api.clients.tio.scans.list()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badips_df = api.query_all(\"\"\"\n",
    "SecurityIncident\n",
    "| where Classification == \"TruePositive\"\n",
    "| mv-expand AlertIds\n",
    "| project tostring(AlertIds)\n",
    "| join SecurityAlert on $left.AlertIds == $right.SystemAlertId\n",
    "| mv-expand todynamic(Entities)\n",
    "| project Entities.Address\n",
    "| where isnotempty(Entities_Address)\n",
    "| distinct tostring(Entities_Address)\n",
    "\"\"\", timespan=pandas.Timedelta(\"45d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = api.query_all(\"find where ClientIP startswith '172.16.' | evaluate bag_unpack(pack_) | take 40000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = api.query_all(\"\"\"union withsource=\"_table\" *\n",
    "| extend _ingestion_time_bin = bin(ingestion_time(), 1h)\n",
    "| summarize take_any(*) by _table, _ingestion_time_bin\n",
    "| project pack=pack_all(true)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "pandas.DataFrame(list(df[\"pack\"].apply(json.loads)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secrets template\n",
    "\n",
    "The below json can be used as a template for saving your own json into *`my_keyvault_name`/squconfig-`my_keyvault_tenantid`* to use with this library:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"config_version\": \"20240101 - added ??? access details\",\n",
    "  \"datalake_blob_prefix\": \"https://???/???\",\n",
    "  \"datalake_subscription\": \"???\",\n",
    "  \"datalake_account\": \"???.blob.core.windows.net\",\n",
    "  \"datalake_container\": \"???\",\n",
    "  \"kql_baseurl\": \"https://raw.githubusercontent.com/???\",\n",
    "  \"azure_dataexplorer\": \"https://???.???.kusto.windows.net/???\",\n",
    "  \"tenant_id\": \"???\",\n",
    "  \"jira_url\": \"https://???.atlassian.net\",\n",
    "  \"jira_username\": \"???@???\",\n",
    "  \"jira_password\": \"???\",\n",
    "  \"runzero_apitoken\": \"???\",\n",
    "  \"abuseipdb_api_key\": \"???\",\n",
    "  \"tenable_access_key\": \"???\",\n",
    "  \"tenable_secret_key\": \"???\",\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
